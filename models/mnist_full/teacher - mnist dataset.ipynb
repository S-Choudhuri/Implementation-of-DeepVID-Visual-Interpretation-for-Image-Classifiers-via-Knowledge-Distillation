{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_classes = 10\n",
    "epochs = 3\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "(x_test,y_test), (x_train,y_train) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (10000, 28, 28, 3)\n",
      "10000 train samples\n",
      "60000 test samples\n"
     ]
    }
   ],
   "source": [
    "# x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "# x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "x_train = np.squeeze(np.stack((x_train,) * 3, -1))\n",
    "x_test = np.squeeze(np.stack((x_test,) * 3, -1))\n",
    "\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"teacher_10-60.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"teacher_10-60.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.concatenate((x_test,x_train))\n",
    "temp1 = np.argmax(np.concatenate((y_test,y_train)), axis = 1)\n",
    "temp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"probabilities.csv\", y_pred1, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_scalar = np.argmax(y_test, axis=1)\n",
    "y_test_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "confusion = confusion_matrix(y_test_scalar, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5754,    1,   18,    0,    3,    6,   24,    0,   45,   72],\n",
       "       [   3, 6482,  134,    0,   73,    0,    4,   22,   17,    7],\n",
       "       [   6,    8, 5840,    0,   15,    1,    0,   34,   39,   15],\n",
       "       [  17,   12,  292, 4924,    3,  217,    0,   11,   45,  610],\n",
       "       [   4,    1,   10,    0, 5760,    0,    4,    3,    0,   60],\n",
       "       [  12,    3,   14,    3,    5, 5248,   66,    0,   14,   56],\n",
       "       [  75,    2,   20,    0,   14,    5, 5780,    0,   20,    2],\n",
       "       [  47,   11,  149,    1,   26,   15,    0, 5911,    7,   98],\n",
       "       [  16,    3,   26,    0,    9,   46,   20,    1, 5533,  197],\n",
       "       [  14,    0,    5,    0,   46,   10,    0,   13,   10, 5851]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9]\n",
      "[5 0 4 1 9]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[0:5])\n",
    "print(y_test_scalar[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))\n",
    "print(len(y_test_scalar))\n",
    "print(len(list(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame(\n",
    "#     {'y_pred': y_pred,\n",
    "#      'y_true': y_test_scalar,\n",
    "#      'image': list(x_test)\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"conf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1 DONE\n",
    "## Part 2 - Pick a random false positive and generate images using VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_test.shape)\n",
    "print(y_test_scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scalar = y_pred\n",
    "y_pred = keras.utils.to_categorical(y_pred_scalar, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 512\n",
    "x_student = []\n",
    "y_student = []\n",
    "# for i in zip(x_test,y_pred_scalar,y_test_scalar):\n",
    "#     if count == 0:\n",
    "#         break\n",
    "#     if i[1] == 2 and i[2] == 7:\n",
    "#         x_student.append(i[0])\n",
    "#         y_student.append(i[1])\n",
    "#         count = count - 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in zip(x_test,y_pred_scalar,y_test_scalar):\n",
    "#     if count == 0:\n",
    "#         break\n",
    "#     if i[1] == 7 and i[2] == 2:\n",
    "#         x_student.append(i[0])\n",
    "#         y_student.append(i[1])\n",
    "#         count -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zip(x_test,y_pred_scalar,y_test_scalar):\n",
    "    if count == 256:\n",
    "        break\n",
    "    if i[1] == 7 and i[2] == 7:\n",
    "        x_student.append(i[0])\n",
    "        y_student.append(i[1])\n",
    "        count = count - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zip(x_test,y_pred_scalar,y_test_scalar):\n",
    "    if count == 0:\n",
    "        break\n",
    "    if i[1] == 2 and i[2] == 2:\n",
    "#         x_student.append(i[0])\n",
    "        x_student.append(x_test[0])\n",
    "        y_student.append(i[1])\n",
    "        count = count - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 28, 28, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_student).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_student_scalar = y_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "# model1.add(Dense(32, activation='relu', input_dim=784))\n",
    "model1.add(Dense(10, activation='softmax',input_dim = 784))\n",
    "model1.compile(optimizer=keras.optimizers.SGD( momentum=0.0, nesterov=False),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_student = keras.utils.to_categorical(y_student_scalar, num_classes=10)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "# model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 28, 28)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_student = np.array(x_student)\n",
    "x_student = x_student[:,:,:,0]\n",
    "x_student.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_student = x_student.reshape(512,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 784)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_student.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 0.9172 - acc: 0.7500 \n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 0s 62us/step - loss: 0.1174 - acc: 1.0000\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0599 - acc: 1.0000\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0402 - acc: 1.0000\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.0303 - acc: 1.0000\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 0s 34us/step - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 0s 34us/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 0s 34us/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 0s 34us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 0s 54us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 0s 59us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 0s 51us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 0s 52us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 0s 54us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 0s 54us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 0s 52us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 0s 55us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 0s 51us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 0s 54us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 0s 91us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 0s 62us/step - loss: 0.0025 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1493a7590>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_student, y_student, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = model1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 10)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "restructured_weights = temp[0].reshape(28,28,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restructured_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restructured_weights = restructured_weights * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restructured_weights  = np.uint8(restructured_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restructured_weights = restructured_weights / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "restructured_weights =  minmax_scale(restructured_weights[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restructured_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x174613090>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.imshow(restructured_weights,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
